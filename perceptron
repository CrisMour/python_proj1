from sklearn import datasets
import numpy as np

# Load the IRIS dataset: iris.data stores the input variables (flower features); iris.target stores the target variables.
iris = datasets.load_iris()

# Use only the "Sepal" features (Sepal Length & Width)
X01 = iris.data[:, [0, 1]]

# Use only the "Petal" features (Petal Length & Width)
X23 = iris.data[:, [2, 3]]

# Use all features (Sepal & Petal Length & Width)
X = iris.data

# Flower Classes: 0 for Iris-Setosa, 1 for Iris-Versicolor, and 2 for Iris-Virginica
y = iris.target

from sklearn.model_selection import train_test_split

# Training and Test sets based on the "Sepal" features
X01_train, X01_test, y_train, y_test = train_test_split(X01, y, test_size = 0.3, random_state = 1, stratify = y)

# Training and Test sets based on the "Petal" features
X23_train, X23_test, y_train, y_test = train_test_split(X23, y, test_size = 0.3, random_state = 1, stratify = y)

# Training and Test sets - all features
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1, stratify = y)
from sklearn.linear_model import Perceptron

# ppn01: Perceptron trained by taking into account only the "Sepal" features
ppn01 = Perceptron(eta0=0.1, random_state=1)
ppn01.fit(X01_train, y_train)

# ppn23: Perceptron trained by taking into account only the "Petal" features
ppn23 = Perceptron(eta0=0.1, random_state=1)
ppn23.fit(X23_train, y_train)

# ppn: Perceptron trained by taking into account all features
ppn = Perceptron(eta0=0.1, random_state=1)
ppn.fit(X_train, y_train)
y_pred = ppn.predict(X_test)

y01_pred = ppn01.predict(X01_test)

y23_pred = ppn23.predict(X23_test)

from sklearn.metrics import accuracy_score

print('Accuracy (All Features): %.3f' % accuracy_score(y_test, y_pred))

from sklearn.metrics import f1_score

print('F1 (All Features): %.3f' % f1_score(y_test, y_pred, average='weighted'))
print("---Hamming---")
print(metrics.hamming_loss(y_test, y_pred, sample_weight=None))
print("---MSE---")
print(metrics.mean_squared_error(y_test, y_pred, sample_weight=None, multioutput='uniform_average', squared=True))
HammingN1C2=metrics.hamming_loss(original_result, preds, sample_weight=None)
MSEN1C2=metrics.mean_squared_error(original_result, preds, sample_weight=None, multioutput='uniform_average', squared=True)
F1N1C2=f1_score(original_result, preds, average='weighted')
AccuracyN1C2=log_regress.score(X = X_test ,y = y_test)
